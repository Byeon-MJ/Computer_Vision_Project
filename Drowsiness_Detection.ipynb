{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyP54+6aYe52bTBw7Cna2QCx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Byeon-MJ/DL_Computer_Vision/blob/main/Drowsiness_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Drowsiness Detection\n",
        "- 얼굴에서 Face Landmark 찾아내고 Eyes Landmark를 이용해 눈을 뜨고있는지 감고있는지 감지\n",
        "- Eyes Landmark 점간의 거리로 EAR(Eye Aspect Ratio) 계수를 계산하여 판단\n",
        "- EAR 계수가 0.2 ~ 0.3 보다 크면 눈을 뜨고있다고 판단"
      ],
      "metadata": {
        "id": "JGo46GYlGAs0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "HUhJPIrJHZQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import dlib\n",
        "import cv2\n",
        "import time"
      ],
      "metadata": {
        "id": "ho53sDOxHmEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# eye landmark 정의\n",
        "RIGHT_EYE = list(range(36, 42))\n",
        "LEFT_EYE = list(range(42, 48))\n",
        "EYES = list(range(36, 48))"
      ],
      "metadata": {
        "id": "gZHfBkegH54U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 얼굴을 감지하는 haarcascade feature 파일\n",
        "face_cascade_name = '/content/gdrive/MyDrive/CV/Face Detection/data/haarcascades/haarcascade_frontalface_alt.xml'\n",
        "\n",
        "# 얼굴 감지 객체 생성\n",
        "face_cascade = cv2.CascadeClassifier()\n",
        "\n",
        "if not face_cascade.load(cv2.samples.findFile(face_cascade_name)):\n",
        "    print('--(!) Error loading face cascade')\n",
        "    exit(0)"
      ],
      "metadata": {
        "id": "u0w84srRIBmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미 학습된 dlib 모델\n",
        "predictor_file = '/content/gdrive/MyDrive/CV/Face Landmark/shape_predictor_68_face_landmarks.dat'\n",
        "\n",
        "# facial landmark 찾는 객체 생성\n",
        "predictor = dlib.shape_predictor(predictor_file)\n",
        "\n",
        "# 원본 동영상 파일\n",
        "file_name = '/content/gdrive/MyDrive/CV/Drowsiness Detection/drowsiness.mp4'\n",
        "# output 동영상 이름\n",
        "output_name = 'drowsiness_detection_video.mp4'\n",
        "\n",
        "# 변수 초기화\n",
        "status = 'Awake'    \n",
        "number_closed = 0   \n",
        "min_EAR = 0.21      # 눈 뜬 간격 최소화 설정\n",
        "closed_limit = 7    # 눈을 감은 patience 수\n",
        "txt = None          # text 문구 초기화\n",
        "color = None        # text 문구 글자색 초기화\n",
        "elapsed_time = 0    # 동영상 detection 하는데 걸린 총 경과시간 초기화"
      ],
      "metadata": {
        "id": "pn3Gl5KTIf9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EAR(eye aspect ratio) 계산 함수 정의\n",
        "def getEAR(points):\n",
        "    A = np.linalg.norm(points[1] - points[5])\n",
        "    B = np.linalg.norm(points[2] - points[4])\n",
        "    C = np.linalg.norm(points[0] - points[3])\n",
        "    return (A + B) / (2.0 * C)"
      ],
      "metadata": {
        "id": "EiCqDQxrJ1vH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detectAndDisplay(image):\n",
        "    global number_closed\n",
        "    global color\n",
        "    global show_frame\n",
        "    global txt\n",
        "    global elapsed_time\n",
        "\n",
        "    # largest_box 초기화\n",
        "    largest_box = 0\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    frame_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    frame_gray = cv2.equalizeHist(frame_gray)\n",
        "    \n",
        "    # face detection\n",
        "    faces = face_cascade.detectMultiScale(frame_gray)\n",
        "\n",
        "    # detect된 box 중에서 largest box 찾기\n",
        "    for (_x, _y, _w, _h) in faces:\n",
        "        SZ = _w * _h\n",
        "        if SZ > largest_box:\n",
        "            largest_box = SZ\n",
        "            x, y, w, h = _x, _y, _w, _h\n",
        "\n",
        "    # box 시작 위치 좌표 저장\n",
        "    x_p, y_p = int(x), int(y)\n",
        "\n",
        "    # 이미지에 box 그리기\n",
        "    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 255), 2)\n",
        "    # dlib에서 사용하는 rect 좌표형식\n",
        "    rect = dlib.rectangle(int(x), int(y), int(x + w), int(y + h))\n",
        "\n",
        "    # 68개 point 좌표\n",
        "    points = np.matrix([[p.x, p.y] for p in predictor(frame_gray, rect).parts()])\n",
        "    show_parts = points[EYES]   # EYES points\n",
        "    right_eye_EAR = getEAR(points[RIGHT_EYE])           # 오른쪽 눈 EAR 계수\n",
        "    left_eye_EAR = getEAR(points[LEFT_EYE])             # 왼쪽 눈 EAR 계수\n",
        "    mean_eye_EAR = (right_eye_EAR + left_eye_EAR) / 2   # 양쪽 눈 EAR 계수 평균값\n",
        "\n",
        "    # 오른쪽 눈 중앙 계산\n",
        "    right_eye_center = np.mean(points[RIGHT_EYE], axis = 0).astype('int')\n",
        "    # 왼쪽 눈 중앙 계산\n",
        "    left_eye_center = np.mean(points[LEFT_EYE], axis = 0).astype('int')\n",
        "    \n",
        "    # 오른쪽 눈 EAR 계수 Display\n",
        "    cv2.putText(image, f'{right_eye_EAR:.2f}', (right_eye_center[0, 0], right_eye_center[0, 1] + 20),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
        "    # 왼쪽 눈 EAR 계수 Display\n",
        "    cv2.putText(image, f'{left_eye_EAR:.2f}', (left_eye_center[0, 0], left_eye_center[0, 1] + 20),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
        "    \n",
        "    # 이미지에 눈을 표현해주기 위해 landmark point 그리기\n",
        "    for (i, point) in enumerate(show_parts):\n",
        "        x = point[0, 0]\n",
        "        y = point[0, 1]\n",
        "        cv2.circle(image, (x, y), 1, (0, 255, 255), -1)\n",
        "\n",
        "    if mean_eye_EAR > min_EAR:  # 눈을 뜨고 있는 경우\n",
        "        color = (0, 255, 0)\n",
        "        status = 'Awake'\n",
        "        number_closed -= 1\n",
        "        if (number_closed < 0):\n",
        "            number_closed = 0\n",
        "    else:                       # 눈을 감고 있는 경우\n",
        "        color = (0, 0, 255)\n",
        "        status = 'Sleep'\n",
        "        number_closed += 1\n",
        "        txt = status + ', Sleep count : ' + str(number_closed) + ' / ' + str(closed_limit)\n",
        "        cv2.putText(image, txt, (x_p+3, y_p-7), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
        "\n",
        "    # video 불러오기\n",
        "    global writer\n",
        "    if writer is None and output_name is not None:\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
        "        writer = cv2.VideoWriter(output_name, fourcc, 30, (image.shape[1], image.shape[0]), True)\n",
        "\n",
        "    # disk에 image write\n",
        "    if writer is not None:\n",
        "        writer.write(image)\n",
        "\n",
        "    # frame 당 처리 시간\n",
        "    frame_time = time.time() - start_time\n",
        "    print(f'Frame time {frame_time:.3f} seconds')\n",
        "    # 총 경과 시간 누적\n",
        "    elapsed_time += frame_time"
      ],
      "metadata": {
        "id": "MtAJd9SZLKiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(file_name)\n",
        "\n",
        "writer = None\n",
        "\n",
        "# 동영상 확인\n",
        "if not cap.isOpened:\n",
        "    print('--(!)Error opening video capture')\n",
        "    exit(0)"
      ],
      "metadata": {
        "id": "4aA-dvuIR6OC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    # 원본 동영상에서 frame 읽기\n",
        "    ret, image = cap.read()\n",
        "\n",
        "    # 원본 동영상에서 더이상 frame을 읽지 못한다면 Exit\n",
        "    if image is None:\n",
        "        # close the video file pointers\n",
        "        cap.release()\n",
        "        # close the writer point\n",
        "        writer.release()\n",
        "        print('--(!) No captured frame -- Break!')\n",
        "        print(f'elapsed time {elapsed_time:.3f} seconds')\n",
        "        break\n",
        "    \n",
        "    detectAndDisplay(image)"
      ],
      "metadata": {
        "id": "DWZzhjuoW2_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AP6vR31GYztP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}