{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMd4EvHXIU9bqyWdWyEsbrQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Byeon-MJ/DL_Computer_Vision/blob/main/Face_Landmark_Video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6tAc3q1KE9EG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5859a038-498c-46d5-b574-f144a8d29b21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import dlib"
      ],
      "metadata": {
        "id": "DfTMTT5kFTYR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 68개 facial landmark 정의\n",
        "RIGHT_EYE = list(range(36, 42))\n",
        "LEFT_EYE = list(range(42, 48))\n",
        "EYES = list(range(36, 48))\n",
        "MOUTH = list(range(48, 68))\n",
        "NOSE = list(range(48, 68))\n",
        "EYEBROWS = list(range(17, 27))\n",
        "JAWLINE = list(range(1, 17))\n",
        "ALL = list(range(0, 68))"
      ],
      "metadata": {
        "id": "uaCWQkBGFvD0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 원본 동영상 파일\n",
        "file_name = '/content/gdrive/MyDrive/CV/Face Landmark/myface.mp4'\n",
        "\n",
        "# output 동영상 이름\n",
        "output_name = 'myface_output_video.mp4'\n",
        "\n",
        "# 학습된 dlib 모델\n",
        "predictor_file = '/content/gdrive/MyDrive/CV/Face Landmark/shape_predictor_68_face_landmarks.dat'\n",
        "\n",
        "# 얼굴 감지 detector 정의\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "\n",
        "# predictor 정의\n",
        "predictor = dlib.shape_predictor(predictor_file)"
      ],
      "metadata": {
        "id": "wjUai2bIGHoL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def DetectAndDisplay(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    rects = detector(gray, 1)   # detector에 의해 얼굴 감지\n",
        "\n",
        "    for (i, rect) in enumerate(rects):\n",
        "        # predictor에 의해서 감지된 landmark point를 x, y 좌표로 계산\n",
        "        points = np.matrix([[p.x, p.y] for p in predictor(gray, rect).parts()])\n",
        "        show_parts = points[ALL]\n",
        "\n",
        "        for (i, point) in enumerate(show_parts):\n",
        "            x = point[0, 0] # x 좌표 값\n",
        "            y = point[0, 1] # y 좌표 값 \n",
        "            cv2.circle(image, (x, y), 1, (0, 255, 255), -1)   # landmark에 점 찍기\n",
        "            cv2.putText(image, f'{i+1}', (x, y - 2), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0, 255, 0), 1) # 점에 숫자 표시\n",
        "    \n",
        "    # video를 disk에 output하기 위해 writer를 초기화한다.\n",
        "    global writer\n",
        "    if writer is None and output_name is not None:\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
        "        writer = cv2.VideoWriter(output_name, fourcc, 30,\n",
        "                                 (image.shape[1], image.shape[0]), True)\n",
        "        \n",
        "    # disk에 frame을 write\n",
        "    if writer is not None:\n",
        "        writer.write(image)"
      ],
      "metadata": {
        "id": "GC_W8nm7Ff8S"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 동영상 읽어옴\n",
        "cap = cv2.VideoCapture(file_name)\n",
        "\n",
        "# 원본 동영상이 오픈되는지 확인\n",
        "writer = None\n",
        "\n",
        "if not cap.isOpened:\n",
        "    print('- -(!)Error opening video capture')\n",
        "    exit(0)\n",
        "\n",
        "while True:\n",
        "    # 원본 동영상에서 frame을 읽는다\n",
        "    ret, image = cap.read()\n",
        "\n",
        "    # 원본 동영상에서 더 이상 frame을 읽지 못했다면 Exit\n",
        "    if image is None:\n",
        "        # close the video file pointers\n",
        "        cap.release()\n",
        "        # close the writer point\n",
        "        writer.release()\n",
        "        print('- -(!) No captured frame - - Break!')\n",
        "        break\n",
        "    \n",
        "    DetectAndDisplay(image)"
      ],
      "metadata": {
        "id": "UHxG_C4bHfG-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "818c11dd-207b-45a2-cf95-e4b0a70927a9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- -(!) No captured frame - - Break!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y1pZM04BKnaS"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}