{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyNfESu0nQD8evJFlfHdzk0C"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Face Encoding"],"metadata":{"id":"LREqqxKN45BT"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"I90gmtN-rL2H"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"markdown","source":["face_recognition 패키지 사용 위해 dlib이 먼저 설치되어있어야함\n","\n","dlib은 컴파일 하기 위해서 cmake 도 설치 필요 > Colab은 기본적으로 둘다 설치되어있음"],"metadata":{"id":"MjVO5iE1rXQr"}},{"cell_type":"code","source":["# # cmake instll\n","# !pip install cmake"],"metadata":{"id":"P4gjc9_Rr5ea"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # dlib install\n","# !pip install dlib"],"metadata":{"id":"cCxw2gapr8YD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# face_recognition install\n","!pip install face_recognition"],"metadata":{"id":"XGWEFftGr_xy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모듈 임포트\n","import cv2\n","import face_recognition\n","import pickle"],"metadata":{"id":"ZRTRY0kasJdX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 학습시킬 이미지 dataset 경로 지정\n","dataset_paths = ['/content/gdrive/MyDrive/CV/Face Recognition/dataset/Mido/']\n","\n","names = ['Mido']       # name 지정\n","number_images = 10      # 학습시킬 이미지 수\n","image_type = '.jpg'     # 이미지 확장자 지정\n","encoding_file = 'encodings.pickle'  # 128개의 vector 값 저장할 파일명\n","model_method = 'cnn'    # cnn or hog. CNN 은 정확도가 높지만 느리고, hog는 빠르지만 정확도가 떨어짐"],"metadata":{"id":"xtbemA9xyIRn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["knownEncodings = []     # 특성값 저장할 배열 지정\n","knownNames = []         # name을 저장할 배열 지정\n","\n","for (i, dataset_path) in enumerate(dataset_paths):\n","    # person name을 names에서 추출\n","    name = names[i]\n","\n","    for idx in range(number_images):\n","        file_name = dataset_path + str(idx + 1) + image_type\n","\n","        image = cv2.imread(file_name)\n","\n","        # 이미지를 face_recognition 에서 처리하기 위해 RGB 형식으로 변경\n","        rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","        # 얼굴을 detection하고 boxing\n","        boxes = face_recognition.face_locations(rgb, model = model_method)\n","\n","        # 얼굴 영역(boxing Area)만 encoding 계산\n","        encodings = face_recognition.face_encodings(rgb, boxes)\n","\n","        # loop over the encodings\n","        for encoding in encodings:\n","            print(file_name, name, encoding)\n","            knownEncodings.append(encoding)\n","            knownNames.append(name)"],"metadata":{"id":"JzCConRQ0fZz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# encoding과 name을 Dictionary 타입으로 저장\n","data = {\"encodings\": knownEncodings, \"names\": knownNames}\n","f = open(encoding_file, 'wb')\n","f.write(pickle.dumps(data))\n","f.close()"],"metadata":{"id":"e43EtqZA16b5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Image Face Recognition\n","이미지에서 얼굴을 Detection 하고 얼굴 영역의 특성값과\n","\n","미리 학습시켜 둔 'encodings.pickle' 파일의 특성값을 비교해서\n","\n","이미지에 특정한 인물이 존재하는지 분류 예측"],"metadata":{"id":"nb_eBNo-3_Dh"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"id":"dEqemeVT415g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # cmake install\n","# !pip install cmake"],"metadata":{"id":"QoOx7A2z5WhY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # dlib install\n","# !pip install dlib"],"metadata":{"id":"hEO_ulNG5cE1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # face_recognition install\n","# !pip install face_recognition"],"metadata":{"id":"Ys2p8p9G5eEl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모듈 임포트\n","import cv2\n","from google.colab.patches import cv2_imshow\n","import face_recognition\n","import pickle\n","import time"],"metadata":{"id":"YpKO1fvS5h1t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 원본 이미지\n","image_file = '/content/gdrive/MyDrive/CV/Face Recognition/doctors1.jpg'\n","\n","# 저장해 두었던 특성 파일\n","encoding_file = '/content/encodings.pickle'\n","\n","# 이름을 모를 경우 Unknown으로 지정\n","unknown_name = 'Unknown'\n","\n","model_method = 'cnn'"],"metadata":{"id":"wym7qmt65qYQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def detectAndDisplay(image):\n","    start_time = time.time()\n","    # 이미지를 face_recognition에서 처리하기 위해 RGB형식으로 변경\n","    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    # 얼굴을 Dectection 하고 Boxing\n","    boxes = face_recognition.face_locations(rgb, model=model_method)\n","\n","    # 얼굴 영역(boxing area)만 encoding\n","    encodings = face_recognition.face_encodings(rgb, boxes)\n","\n","    # detection 된 얼굴의 이름을 저장할 배열\n","    names = []\n","\n","    for encoding in encodings:\n","        # boxing 된 특성이 pickle 파일의 encodings 과 매칭 되는지 찾기\n","        matches = face_recognition.compare_faces(data['encodings'], encoding)\n","        print(matches)\n","        name = unknown_name     # 'Unknown'으로 초기화\n","\n","        # check to see if we have found a match\n","        if True in matches and matches.count(True) > 5:     # 동양인은 구분을 잘 못해서 True값의 최소 신뢰도 설정 (and 이후)\n","            # 매칭된 pickle 파일의 True 인덱스 번호를 찾는다.\n","            matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n","            counts = {}      # 매칭된 얼굴별로 이름과 겹친 Count 수를 Dictionary 타입으로 저장\n","\n","            for i in matchedIdxs:\n","                # 매칭된 True 인덱스 번호의 'names' value를 가져옴\n","                name = data['names'][i]\n","                # count dict의 'name' 키 값의 value에 count 누적\n","                counts[name] = counts.get(name, 0) + 1\n","\n","            # count dict에서 key값(이름)들 중에서 가장 value 값이 큰 key값을 가져옴\n","            name = max(counts, key=counts.get)\n","\n","        \n","        # names 배열에 이름 추가\n","        names.append(name)\n","\n","\n","    # detection 된 얼굴의 boxing 위치 좌표와 이름 매칭\n","    for ((top, right, bottom, left), name) in zip(boxes, names):\n","        color = (0, 255, 0)     # boxing color\n","        line = 2                # boxing line 두께\n","        if(name == unknown_name):\n","            color = (0, 0, 255)\n","            line = 1\n","            name = ''   # unknown은 이름 표시x\n","\n","        cv2.rectangle(image, (left, top), (right, bottom), color, line)\n","        y = top - 15 if top - 15 > 15 else top + 15\n","        cv2.putText(image, name, (left, y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, line)\n","\n","    end_time = time.time()\n","    process_time = end_time - start_time\n","    print('= = = A frame took {:.3f} seconds'.format(process_time))\n","\n","    # show the output image\n","    cv2_imshow(image)"],"metadata":{"id":"d5dcsWBR6I-A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 저장된 encodings 파일 불러오기\n","data = pickle.loads(open(encoding_file, 'rb').read())"],"metadata":{"id":"VqCZfwUX6--2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 원본 이미지 로드\n","image = cv2.imread(image_file)"],"metadata":{"id":"4lginu8o7K0V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["detectAndDisplay(image)"],"metadata":{"id":"ijCS5xgk7OMV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### face_recognition 특징\n","* face_recognition 패키지는 정확도면에서 한계\n","* 실전에서는 face landmark를 활용한 전처리 과정(Alignment)를 통해 정확도를 높이고있다.\n","* 동양인들 끼리의 얼굴 인식은 잘 안된다."],"metadata":{"id":"JP8CdG6VPn7c"}},{"cell_type":"code","source":[],"metadata":{"id":"GXNpxhFEP2MK"},"execution_count":null,"outputs":[]}]}