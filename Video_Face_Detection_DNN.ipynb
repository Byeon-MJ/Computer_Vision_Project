{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyPcSoUx21chjd4rI3rEUXmI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"mrFnnuJre_2b"},"outputs":[],"source":["# Drive mount\n","from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["!git clone https://github.com/gopinath-balu/computer_vision"],"metadata":{"id":"W1Nv2eMAhlZy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모듈 임포트\n","import cv2\n","import numpy as np\n","import time\n","import io\n","import base64\n","from IPython.display import HTML"],"metadata":{"id":"vYTBntuMfJxU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 원본 동영상 Display\n","video = io.open('/content/gdrive/MyDrive/CV/Face Detection/data/video/son.mp4', 'r+b').read()\n","encoded = base64.b64encode(video)\n","HTML(data = '''<video width='50%' controls>\n","                    <source src = 'data:video/mp4;base64,{0}' type = 'video/mp4'/>\n","                    </video>'''.format(encoded.decode('ascii')))"],"metadata":{"id":"BYNeBg1dfWpL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# DNN 학습 모델(caffemodel) 사용 정의\n","model_name = '/content/computer_vision/CAFFE_DNN/res10_300x300_ssd_iter_140000.caffemodel'\n","\n","# 모델 Architecture 정의\n","prototxt_name = '/content/computer_vision/CAFFE_DNN/deploy.prototxt.txt'\n","\n","# Detection 최소 확률(신뢰도) 50% 정의\n","min_confidence = 0.5\n","\n","# 원본 동영상 정의\n","file_name = '/content/gdrive/MyDrive/CV/Face Detection/data/video/son.mp4'\n","\n","# detection 결과물(output 동영상) 이름 정의\n","output_name = 'son_output_video.mp4'"],"metadata":{"id":"9y5A7YjljBhh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Face Detection & Display 함수 정의\n","def detectAndDisplay(frame):\n","\n","    # caffemodel의 weight 값과 모델 네트워크 구성을 불러와서 모델 정의\n","    model = cv2.dnn.readNetFromCaffe(prototxt_name, model_name)\n","\n","    # 이미지를 300x300 으로 size를 조정하고 blob 를 만든다.\n","    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, \n","                                 (300, 300), (104.0, 177.0, 123.0))\n","\n","    # blob을 모델에 넣는다\n","    model.setInput(blob)\n","\n","    # detection을 수행\n","    detections = model.forward()\n","\n","    # detections 한 수만큼 루프가 돈다.\n","    for i in range(0, detections.shape[2]):\n","\n","        confidence = detections[0, 0, i, 2]  # confidence 는 detection한 확률을 나타냄\n","\n","        # min_confidence 보다 큰 경우에만 detection으로 인정함\n","        if confidence > min_confidence:\n","            (height, width) = frame.shape[:2]\n","            \n","            # detection 된 영역을 boxing\n","            # 상대적 좌표 * np.array([width, height, width, height]) 절대적인 boxing 좌표 구하기\n","            box = detections[0, 0, i, 3:7] * np.array([width, height, width, height])\n","            (startX, startY, endX, endY) = box.astype(\"int\")\n","            \n","            # print(confidence, startX, startY, endX, endY)\n","\n","            # 얼굴에 bounding box(사각형)를 그리고 확률값 표시\n","            text = '{:.2f}%'.format(confidence * 100)\n","            y = startY - 10 if startY - 10 > 10 else startY + 10\n","            cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n","            cv2.putText(frame, text, (startX, y),\n","                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n","            \n","    # video를 disk 에 output 하기 위해 writer 초기화\n","    global writer\n","    if writer is None and output_name is not None:\n","        fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n","        writer = cv2.VideoWriter(output_name, fourcc, 30,\n","                                 (frame.shape[1], frame.shape[0]), True)\n","        \n","    # disk에 frame을 write\n","    if writer is not None:\n","        writer.write(frame)"],"metadata":{"id":"k_qHqkhGjTaY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 원본 동영상에서 video stram 읽기\n","cap = cv2.VideoCapture(file_name)\n","writer = None\n","if not cap.isOpened:\n","    print('- -(!)Error opening video capture')\n","    exit(0)\n","while True:\n","    ret, frame = cap.read()\n","    if frame is None:\n","        # close the video file pointers\n","        cap.release()\n","        # close the writer point\n","        writer.release()\n","        print('- -(!) No Captured Frame - - Break!')\n","        break\n","    detectAndDisplay(frame)"],"metadata":{"id":"VlPHZPiC0XNn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"mPAiXEccm3JK"},"execution_count":null,"outputs":[]}]}