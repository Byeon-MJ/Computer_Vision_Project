{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyPiVPWaMsx0IwN0cMttBUDs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"JX61s5XvkwmF"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["# 모듈 임포트\n","import cv2\n","import numpy as np\n","import time\n","import io\n","import base64\n","from IPython.display import HTML"],"metadata":{"id":"t8lU7APek5Pd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 원본 동영상 Display\n","video = io.open('/content/gdrive/MyDrive/CV/Object Detection_YOLO/video/video/street.mp4',\n","               'r+b').read()\n","\n","encoded = base64.b64encode(video)\n","HTML(data = '''<video width = '30%' controls>\n","                <source src = 'data:video/mp4;base64,{0}' type = 'video/mp4'/>\n","                </video>'''.format(encoded.decode('ascii')))"],"metadata":{"id":"b6Ijl3zWlsJL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Detection 할 원본 동영상\n","file_name = '/content/gdrive/MyDrive/CV/Object Detection_YOLO/video/video/street.mp4'\n","min_confidence = 0.5\n","output_name = 'street_output_video.mp4'\n","elapsed_time = 0        # 총 경과시간 초기화"],"metadata":{"id":"NK-f0hP9mVH9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load YOLO\n","net = cv2.dnn.readNet('/content/gdrive/MyDrive/CV/Object Detection_YOLO/yolov3.weights',\n","                      '/content/gdrive/MyDrive/CV/Object Detection_YOLO/yolov3.cfg')\n","classes = []\n","\n","with open('/content/gdrive/MyDrive/CV/Object Detection_YOLO/coco.names', 'r') as f:\n","    # 80개의 Object(class)를 구분할 수 있는 Object의 이름을 classes 배열에 넣는다.\n","    classes = [line.strip() for line in f.readlines()]\n","\n","layer_names = net.getLayerNames()\n","output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n","\n","# Object 마다 컬러를 하나씩 다르게 지정\n","colors = np.random.uniform(0, 255, size = (len(classes), 3))"],"metadata":{"id":"BhAgd9-RtGx7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# detect & Display 함수 정의\n","def detectAndDisplay(frame):\n","    start_time = time.time()\n","    img = cv2.resize(frame, None, fx=0.9, fy=0.9)\n","    height, width, channels = img.shape\n","\n","    # YOLOv3의 Detecting model 3가지(320*320, 416*416, 608*608)\n","    blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n","\n","    net.setInput(blob)\n","    outs = net.forward(output_layers)\n","\n","    class_ids = []\n","    confidences = []\n","    boxes = []\n","\n","    for out in outs:\n","        for detection in out:\n","            scores = detection[5:]\n","            class_id = np.argmax(scores)\n","            confidence = scores[class_id]\n","\n","            if confidence > min_confidence:\n","                # Object detected\n","                center_x = int(detection[0] * width)\n","                center_y = int(detection[1] * height)\n","                w = int(detection[2] * width)\n","                h = int(detection[3] * height)\n","\n","                # Rectangle coordinates\n","                x = int(center_x - w / 2)\n","                y = int(center_y - h / 2)\n","\n","                boxes.append([x, y, w, h])              # boxing 정보 저장\n","                confidences.append(float(confidence))   # 신뢰도 저장\n","                class_ids.append(class_id)              # Class id 저장\n","\n","    # 박스 안에 박스(노이즈)를 하나로 만들어준다.\n","    indexes = cv2.dnn.NMSBoxes(boxes, confidences, min_confidence, 0.4)\n","    font = cv2.FONT_HERSHEY_PLAIN\n","\n","    for i in range(len(boxes)):\n","        if i in indexes:\n","            x, y, w, h = boxes[i]\n","\n","            # Class 이름, 신뢰도 표시\n","            label = '{}: {:.2f}'.format(classes[class_ids[i]], confidences[i] * 100)\n","\n","            print(i, label)\n","            color = colors[i]\n","            cv2.rectangle(img, (x, y), (x + w, y + h), color, 1)\n","            cv2.rectangle(img, (x, y - 20), (x + w, y), color, -1)\n","            cv2.putText(img, label, (x + 5, y - 5), font, 1, (255, 255, 255), 1)\n","\n","    process_time = time.time() - start_time\n","\n","    global elapsed_time\n","    elapsed_time += process_time     # 총 경과시간 누적\n","\n","    print('= = = A frame took {:.3f} seconds'.format(process_time))\n","\n","    # video 를 disk에 output 하기 위해 writer 초기화\n","    global writer\n","    if writer is None and output_name is not None:\n","        fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n","        writer = cv2.VideoWriter(output_name, fourcc, 30,\n","                                (img.shape[1], img.shape[0]), True)\n","    # disk에 frame write\n","    if writer is not None:\n","        writer.write(img)"],"metadata":{"id":"EyIlfGP7tAH-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 원본 동영상에서 video stream 읽어오기\n","cap = cv2.VideoCapture(file_name)\n","writer = None\n","if not cap.isOpened:\n","    print('- -(!)Error opening video capture')\n","    exit(0)\n","\n","while True:\n","    ret,frame = cap.read()\n","    if frame is None:\n","        # close the video file pointers\n","        cap.release()\n","\n","        # close the writer point\n","        writer.release()\n","        print('- -(!) No captured frame - - Break!')\n","        print('elapsed time {:.3f} seconds'.format(elapsed_time))\n","        break\n","\n","    detectAndDisplay(frame)"],"metadata":{"id":"EpzIfvtStcg0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"wTrnKsN2jnRr"},"execution_count":null,"outputs":[]}]}